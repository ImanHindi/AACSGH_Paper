{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"DailyResourceConsumption\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "orgin_path = \"D:\\\\Iman\\\\AGHC\\\\CherryTomato\\Data\\\\\"\n",
    "filenames = ['AICU', 'Automatoes',\n",
    "             'Digilog', 'IUACAAS', \n",
    "             'Reference', 'TheAutomators'\n",
    "             ]\n",
    "daily_Avg=dict()\n",
    "Daily_Resource_Consumption=dict()\n",
    "greenhouse_climate=dict()\n",
    "for filename in filenames:\n",
    "    path=Path(orgin_path+filename+'\\\\Resources.csv')\n",
    "    Daily_Resource_Consumption[filename] = pd.read_csv(path,parse_dates=[\"%Time \"],low_memory=False).set_index('%Time ').astype(float)\n",
    "    #print(Daily_Resource_Consumption[filename].index.shape)\n",
    "    Daily_Resource_Consumption[filename]['%Time_t']=Daily_Resource_Consumption[filename].index.astype(str)+\"_\"+filename\n",
    "    Daily_Resource_Consumption[filename]=Daily_Resource_Consumption[filename].set_index('%Time_t')\n",
    "    path=Path(orgin_path+filename+'\\\\GreenhouseClimate.csv')\n",
    "    greenhouse_climate[filename]=pd.read_csv(path,parse_dates=[\"%time\"],low_memory=False).set_index('%time').astype(float)\n",
    "    \n",
    "    #greenhouse_climate[filename].drop(columns=[  'AssimLight', 'BlackScr', 'CO2air', 'EC_drain_PC', 'EnScr', 'HumDef',\n",
    "    #    'Rhair','Tot_PAR', 'Tot_PAR_Lamps','VentLee', 'Ventwind', 'co2_dos'],inplace=True)\n",
    "    sp_vip_paired_attributtes=[ [('assim_sp','assim_vip'),('assim_vip','assim_sp')],\n",
    "                            [('co2_sp','co2_vip'),('co2_vip','co2_sp')],\n",
    "                            [('dx_sp','dx_vip'),('dx_vip','dx_sp')],\n",
    "                            [('int_blue_sp','int_blue_vip'),('int_blue_vip','int_blue_sp')],\n",
    "                            [('int_farred_sp','int_farred_vip'),('int_farred_vip','int_farred_sp')],\n",
    "                            [('int_red_sp','int_red_vip'),('int_red_vip','int_red_sp')], \n",
    "                            [('int_white_sp','int_white_vip'),('int_white_vip','int_white_sp')],\n",
    "                            [('scr_blck_sp','scr_blck_vip'),('scr_blck_vip','scr_blck_sp')],\n",
    "                            [('scr_enrg_sp','scr_enrg_vip'),('scr_enrg_vip','scr_enrg_sp')],\n",
    "                            [('t_grow_min_sp','t_grow_min_vip'),('t_grow_min_vip','t_grow_min_sp')],\n",
    "                            [('t_heat_sp','t_heat_vip'),('t_heat_vip','t_heat_sp')],\n",
    "                            [('t_rail_min_sp','t_rail_min_vip'),('t_rail_min_vip','t_rail_min_sp')],\n",
    "                            [('t_vent_sp','t_ventlee_vip'),('t_ventlee_vip','t_vent_sp')],\n",
    "                            [('water_sup_intervals_sp_min','water_sup_intervals_vip_min'),('water_sup_intervals_vip_min','water_sup_intervals_sp_min')],\n",
    "                            [('window_pos_lee_sp','window_pos_lee_vip'),('window_pos_lee_vip','window_pos_lee_sp')],\n",
    "                            ]\n",
    "    norm_mean_difference=[]\n",
    "    for sp_vip_paired_attributte in sp_vip_paired_attributtes: \n",
    "        for (sp, vip) in sp_vip_paired_attributte:\n",
    "            x=greenhouse_climate[filename].iloc[(np.where(greenhouse_climate[filename][sp].isnull()))][vip]\n",
    "            #print(teams_ghc[sp])\n",
    "            difference=(greenhouse_climate[filename][sp]-greenhouse_climate[filename][vip]).mean()\n",
    "            mean_difference=difference/(greenhouse_climate[filename][sp].mean())\n",
    "            norm_mean_difference.append([sp,vip,mean_difference])\n",
    "\n",
    "            #print(f'{sp},{vip} difference={norm_mean_difference}')\n",
    "            #print(x.index)\n",
    "            for i in x.index:\n",
    "                #print(i)\n",
    "                greenhouse_climate[filename].loc[i,sp]= greenhouse_climate[filename].loc[i,vip]#.iloc[i][vip]\n",
    "                #print(i,teams_ghc.loc[i,sp]) \n",
    "            #plt.figure()\n",
    "            #correlation = greenhouse_climate[filename].corr()[vip][sp]\n",
    "            #corr1=greenhouse_climate[filename].corr()[vip].sort_values(ascending=False)\n",
    "            #corr1.plot(kind='bar',title=f'{vip} SP-VIP Correlation',figsize=(18, 6),fontsize=12)\n",
    "            ##plt.show\n",
    "            #save_fig(f'{vip}SP-VIP Correlation')\n",
    "            #print(f\"correlation between {vip} and {sp}=\",correlation)\n",
    "            #plt.show\n",
    "    norm_mean_difference     \n",
    "\n",
    "\n",
    "\n",
    "    #fill missing values\n",
    "    for gh_attribute in greenhouse_climate[filename].columns:\n",
    "        x=greenhouse_climate[filename].iloc[(np.where(greenhouse_climate[filename][gh_attribute].isnull()))][gh_attribute]\n",
    "        for i in reversed(x.index):\n",
    "            if i.day+(1)< greenhouse_climate[filename].index[-1].day:\n",
    "                #print(i+(12*24))\n",
    "                d=i\n",
    "                #print(d)\n",
    "\n",
    "                d = d.replace(day=d.day+1)\n",
    "\n",
    "                #print(d)\n",
    "                greenhouse_climate[filename].loc[i,gh_attribute]= greenhouse_climate[filename].loc[d,gh_attribute]\n",
    "                #print(i+(12*24),teams_ghc.loc[i,gh_attribute])\n",
    "    for gh_attribute in greenhouse_climate[filename].columns:\n",
    "        x=greenhouse_climate[filename].iloc[(np.where(greenhouse_climate[filename][gh_attribute].isnull()))][gh_attribute]\n",
    "        for i in x.index:\n",
    "            if i.day-(1)>= 0:\n",
    "                #print(i+(12*24))\n",
    "                d=i\n",
    "                #print(d)\n",
    "                d = d.replace(day=d.day-1)\n",
    "                #print(d)\n",
    "                greenhouse_climate[filename].loc[i,gh_attribute]= greenhouse_climate[filename].loc[d,gh_attribute]\n",
    "                #print(i+(12*24),teams_ghc.loc[i,gh_attribute])\n",
    "\n",
    "    #print(greenhouse_climate[filename].groupby(greenhouse_climate[filename].index.date).mean())\n",
    "    \n",
    "    daily_Avg[filename]=greenhouse_climate[filename].groupby(greenhouse_climate[filename].index.date).mean()\n",
    "    #daily_Avg[filename]['water_sup_intervals_vip_min']=greenhouse_climate[filename].groupby(greenhouse_climate[filename].index.date).sum()['water_sup_intervals_vip_min']\n",
    "    daily_Avg[filename]['%time_t']=daily_Avg[filename].index.astype(str)+\"_\"+filename\n",
    "    daily_Avg[filename]=daily_Avg[filename].set_index('%time_t')\n",
    "    #print(daily_Avg[filename].index[-1])\n",
    "    daily_Avg[filename].drop(daily_Avg[filename].index[-1],axis=0,inplace=True)\n",
    "    greenhouse_climate[filename]['%time_t']=greenhouse_climate[filename].index.astype(str)+\"_\"+filename\n",
    "    greenhouse_climate[filename]=greenhouse_climate[filename].set_index('%time_t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for resource in Daily_Resource_Consumption[filename].columns:\n",
    "    for i in range(len(filenames)):\n",
    "        Daily_Resource_Consumption[filenames[i]][\"2019-12-16 00:00:00\" : \"2019-12-26 00:00:00\"][resource].plot(ylabel=resource,grid=True, marker=\".\", figsize=(18, 6),legend=True,label=f'{filenames[i]}')\n",
    "    plt.title(f'green_house_{resource}_time_series_plot for all Teams ')\n",
    "    plt.legend()\n",
    "    save_fig(f'green_house_{resource}_time_series_plot ')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teams_drc=pd.concat([Daily_Resource_Consumption[filenames[0]],Daily_Resource_Consumption[filenames[1]],\n",
    "                    Daily_Resource_Consumption[filenames[2]],Daily_Resource_Consumption[filenames[3]],\n",
    "                    Daily_Resource_Consumption[filenames[4]],Daily_Resource_Consumption[filenames[5]]], axis=0)\n",
    "\n",
    "teams_ghc=pd.concat([greenhouse_climate[filenames[0]],greenhouse_climate[filenames[1]],\n",
    "                     greenhouse_climate[filenames[2]],greenhouse_climate[filenames[3]],\n",
    "                     greenhouse_climate[filenames[4]],greenhouse_climate[filenames[5]]], axis=0)\n",
    "\n",
    "teams_da=pd.concat([ daily_Avg[filenames[0]],daily_Avg[filenames[1]],\n",
    "                     daily_Avg[filenames[2]],daily_Avg[filenames[3]],\n",
    "                     daily_Avg[filenames[4]],daily_Avg[filenames[5]]], axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.astype(float).isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.hist(figsize=(20,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teams_da.shape)\n",
    "print(teams_drc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for num_attribute in teams_drc.columns:\n",
    "    \n",
    "    teams_drc[\"2019-12-16_Automatoes\" : \"2020-05-29_Automatoes\"][num_attribute].plot(ylabel=num_attribute,xlabel='Day Index',grid=True, marker=\".\", figsize=(18, 6),title=num_attribute)\n",
    "    \n",
    "    save_fig(f'dailyConsumptionsof_{num_attribute}_time_series_plot')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teams_da.drop(['assim_vip', 'co2_vip',  'dx_vip',\n",
    "#       'int_blue_vip', 'int_farred_vip',\n",
    "#       'int_red_vip', 'int_white_vip',\n",
    "#        'scr_blck_vip', \n",
    "#       'scr_enrg_vip', 't_grow_min_vip', \n",
    "#       't_heat_vip', 't_rail_min_vip', \n",
    "#       't_ventlee_vip', 't_ventwind_vip',\n",
    "#       'water_sup_intervals_vip_min',\n",
    "#       'window_pos_lee_vip'],axis=1,inplace=True)\n",
    "teams_da.drop(['assim_sp', 'co2_sp',  'dx_sp',\n",
    "           'int_blue_sp', 'int_farred_sp','scr_blck_sp',\n",
    "           'int_red_sp', 'int_white_sp','t_grow_min_sp',\n",
    "           't_heat_sp', 't_rail_min_sp',\n",
    "           't_vent_sp','water_sup_intervals_sp_min',\n",
    "           'window_pos_lee_sp','scr_enrg_sp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_da.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_drc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teams_drc.drop('%Time_t',axis=1,inplace=True)\n",
    "#teams_ghc.drop('%time_t',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_drc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teams_ghc.drop(columns=[  'AssimLight', 'BlackScr', 'CO2air', 'EC_drain_PC', 'EnScr', 'HumDef',\n",
    "#       'PipeGrow', 'PipeLow', 'Rhair', 'Tair', 'Tot_PAR', 'Tot_PAR_Lamps',\n",
    "#       'VentLee', 'Ventwind', 'co2_dos', 'Cum_irr','water_sup'],inplace=True)\n",
    "\n",
    "features = ['assim_sp', 'assim_vip', 'co2_dos', 'co2_sp',\n",
    "       'co2_vip', 'dx_sp', 'dx_vip', 'int_blue_sp', 'int_blue_vip',\n",
    "       'int_farred_sp', 'int_farred_vip', 'int_red_sp', 'int_red_vip',\n",
    "       'int_white_sp', 'int_white_vip', 'scr_blck_sp',\n",
    "       'scr_blck_vip', 'scr_enrg_sp', 'scr_enrg_vip', 't_grow_min_sp',\n",
    "       't_grow_min_vip', 't_heat_sp', 't_heat_vip', 't_rail_min_sp',\n",
    "       't_rail_min_vip', 't_vent_sp', 't_ventlee_vip', 't_ventwind_vip',\n",
    "       'water_sup_intervals_sp_min', 'window_pos_lee_sp', 'window_pos_lee_vip',\n",
    "       'water_sup_intervals_vip_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ghc.index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teams_drc['Irr']=teams_drc['Irr']-teams_drc['Drain']\n",
    "#teams_drc.drop(['Drain'],axis=1,inplace=True)\n",
    "teams_drc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filenames)):\n",
    "\n",
    "    greenhouse_climate[filenames[i]].drop(['assim_sp', 'co2_sp',  'dx_sp',\n",
    "           'int_blue_sp', 'int_farred_sp','scr_blck_sp',\n",
    "           'int_red_sp', 'int_white_sp','t_grow_min_sp',\n",
    "           't_heat_sp', 't_rail_min_sp', \n",
    "           't_vent_sp','water_sup_intervals_sp_min',\n",
    "           'window_pos_lee_sp','scr_enrg_sp'],axis=1,inplace=True)\n",
    "    daily_Avg[filenames[i]].drop(['assim_sp', 'co2_sp',  'dx_sp',\n",
    "           'int_blue_sp', 'int_farred_sp','scr_blck_sp',\n",
    "           'int_red_sp', 'int_white_sp','t_grow_min_sp',\n",
    "           't_heat_sp', 't_rail_min_sp',\n",
    "           't_vent_sp','water_sup_intervals_sp_min',\n",
    "           'window_pos_lee_sp','scr_enrg_sp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_drc.set_index(teams_da.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_drc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data=pd.concat([ teams_da,teams_drc], axis=1)\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes=['Heat_cons'\t,'ElecHigh',\t'ElecLow',\t'CO2_cons',\t'Irr','Drain']\n",
    "for  attribute in attributes:\n",
    "    correlation=daily_data.corr()[attribute].sort_values(ascending=False).drop(teams_drc.columns)\n",
    "    plt.figure()\n",
    "    correlation.plot(kind='bar',title=f'{attribute} Correlation with features',figsize=(18, 6),fontsize=12)\n",
    "    plt.show\n",
    "    save_fig(f'{attribute}CorrelationwithFeatures')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "teams_data=dict()\n",
    "corr=dict()\n",
    "team_corr=dict()\n",
    "filenames = ['AICU', 'Automatoes',\n",
    "             'Digilog', 'IUACAAS', \n",
    "             'Reference', 'TheAutomators'\n",
    "             ]\n",
    "for i in range(len(filenames)):\n",
    "\n",
    "    merged_data=pd.concat([ daily_Avg[filenames[i]],Daily_Resource_Consumption[filenames[i]]], axis=1)\n",
    "    \n",
    "    correlation_matrix = merged_data.corr()\n",
    "    \n",
    "    outputs=merged_data.columns[-6:]\n",
    "    \n",
    "    for output in outputs:\n",
    "        corr[output]=merged_data[merged_data.columns].corr()[output].sort_values(ascending=False)\n",
    "        corr[output].drop(outputs,axis=0,inplace=True)\n",
    "        corr[output].plot(kind='bar',title=f'{filenames[i]} {output} Correlation with SP',figsize=(18, 6),fontsize=12)\n",
    "        plt.show()\n",
    "        save_fig(f'{filenames[i]} {output} Correlation with SP')\n",
    "        \n",
    "    team_corr[filenames[i]]=corr\n",
    "    # Plotting the correlation matrix\n",
    "    #plt.figure(figsize=(15, 10))\n",
    "    #sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "    #plt.title('Correlation Matrix Between SP Features and Crop Parameters')\n",
    "    #plt.show()\n",
    "    \n",
    "    #print('control_features',merged_data.columns[:-3])\n",
    "    control_features = merged_data.columns[:-6]\n",
    "    \n",
    "    #print('output',merged_data.columns[-5:-2])\n",
    "    \n",
    "    #for control_feature in control_features:\n",
    "    #    plt.figure(figsize=(15, 6))\n",
    "    #    sns.lineplot(data=merged_data[control_feature], palette='tab11',legend=True)           \n",
    "    #    sns.lineplot(data=merged_data[outputs], palette='tab10')\n",
    "#\n",
    "    #    plt.title(f'Time Series of {control_feature} and CropParameters for {filenames[i]}')\n",
    "    #    plt.xlabel('Date')\n",
    "    #    plt.legend(loc='right')\n",
    "    #    plt.show()\n",
    "    #for control_feature in control_features:\n",
    "    #    plt.figure(figsize=(15, 6))\n",
    "    #    for output in outputs:\n",
    "    #        sns.lineplot(x=merged_data[control_feature],y=merged_data[output], palette='tab10')\n",
    "    #        #sns.lineplot(data=teams_ghc_weekly[output], palette='tab10')\n",
    "    #plt.title(f'{control_feature} with CropParameters {filenames[i]}')\n",
    "    #plt.xlabel(control_feature)\n",
    "    #plt.ylabel('CropParameters')\n",
    "    #plt.legend(loc='best')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Step 8: Effect of Specific Control Setpoints on Crop Parameters\n",
    "    for control_feature in control_features:\n",
    "        for output in outputs:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.scatterplot(data=merged_data, x=control_feature, y=output)\n",
    "            sns.regplot(data=merged_data, x=control_feature, y=output, scatter=False, color='red')\n",
    "            plt.title(f'Effect of {control_feature} on {output} for {filenames[i]}')\n",
    "            plt.show()\n",
    "\n",
    "    teams_data[filenames[i]]=merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "#add 'AssimLight', 'CO2air', 'Cum_irr','HumDef', 'Rhair', 'Tair', 'Tot_PAR','Tot_PAR_Lamps', 'co2_dos',\n",
    "features=[       'co2_vip', 'dx_vip', 'int_blue_vip', 'int_farred_vip', 'int_red_vip',\n",
    "       'int_white_vip', 'pH_drain_PC', 'scr_blck_vip','t_heat_vip',\n",
    "       'water_sup_intervals_vip_min']\n",
    "# Step 10: Advanced Visualizations\n",
    "for feature in features:\n",
    "    for output in outputs:\n",
    "        # Interactive Scatter Plot with Plotly\n",
    "        fig = px.scatter(daily_data, x=feature, y=output, color=[filenames[i] for x in range(166) for i in range(len(filenames))])       \n",
    "        fig.update_layout(title=f'Interactive Scatter Plot: {feature} vs. {output}')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "# Violin Plot to Compare Distributions\n",
    "for output in outputs:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(data=daily_data, x=[filenames[i] for x in range(166)  for i in range(len(filenames))], y=output)\n",
    "    plt.title('Violin Plot for Stem Elongation Across Teams')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filenames)):\n",
    "        Daily_Resource_Consumption[filenames[i]]['%time'] = pd.to_datetime(Daily_Resource_Consumption[filenames[i]].index.str.split('_').str[0])\n",
    "        Daily_Resource_Consumption[filenames[i]].set_index('%time', inplace=True)  # Set datetime as the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in Daily_Resource_Consumption[filename].columns:\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.gca()\n",
    "    for i in range(len(filenames)):\n",
    "        \n",
    "        davg = Daily_Resource_Consumption[filenames[i]][feature]#.resample('h').mean()  # compute the mean for each hour\n",
    "        #weekly_avg = Weekly_Crop_Parameters[filenames[i]][output].resample('W').mean()\n",
    "        #print(dayly_avg)\n",
    "        period=slice(\"2019-12-16 00:00:00\", \"2020-05-30 00:00:00\")\n",
    "        rolling_average_daily = davg[period].rolling(window=30).mean()\n",
    "        #rolling_average_weekly = weekly_avg[period].rolling(window=4).mean()\n",
    "\n",
    "        rolling_average_daily.plot(grid=True,legend=True,label=f'{filenames[i]}')\n",
    "    ax.set_xlabel(xlabel='%time')\n",
    "    ax.set_ylabel(ylabel=f'{feature}')\n",
    "    ax.set_title(f'{feature} time series of Teams')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#add the legend for each line of plot which represent the file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import json   \n",
    "from math import floor\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import vgg19\n",
    "from keras.layers import AveragePooling2D,Dropout,Flatten,Dense,Activation,Input,MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,multilabel_confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = daily_data[attributes]\n",
    "data = daily_data.drop(attributes,axis=1)\n",
    "\n",
    "np.save('daily_data.npy', data)\n",
    "np.save('daily_labels.npy', labels)\n",
    "\n",
    "print('data',data.shape)\n",
    "print('labels',labels.shape)\n",
    "\n",
    "#data = np.load(\"data.npy\")\n",
    "#labels = np.load(\"labels.npy\")\n",
    "\n",
    "#testY=ss_y.transform(testY)\n",
    "\n",
    "#testY=pd.DataFrame(testY,columns=[labels.columns])\n",
    "\n",
    "\n",
    "#splitting the data into test and train\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,shuffle=True,\n",
    "\ttest_size=0.2, random_state=42)\n",
    "\n",
    "#(trainX, validX, trainY, validY) = train_test_split(trainX, trainY,shuffle=True,\n",
    "#\ttest_size=0.2, random_state=42)\n",
    "\n",
    "ss_x=MinMaxScaler()\n",
    "trainX=ss_x.fit_transform(trainX)\n",
    "testX=ss_x.transform(testX)\n",
    "\n",
    "ss_y=MinMaxScaler()\n",
    "trainY=ss_y.fit_transform(trainY)\n",
    "testY=ss_y.transform(testY)\n",
    "\n",
    "print('trainX',trainX.shape)\n",
    "print('trainY',trainY.shape)\n",
    "print('testX',testX.shape)\n",
    "print('testY',testY.shape)\n",
    "#print('validX',validX.shape)\n",
    "#print('validY',validY.shape)\n",
    "\n",
    "\n",
    "#SS = StandardScaler()\n",
    "#\n",
    "#trainX = SS.fit_transform(trainX)\n",
    "#validX = SS.transform(validX)\n",
    "#testX= SS.transform(testX)\n",
    "\n",
    "\n",
    "np.save('trainX_DailyResourceConsumptionRegression.npy', trainX)\n",
    "np.save('trainY_DailyResourceConsumptionRegression.npy', trainY)\n",
    "\n",
    "np.save('testX_DailyResourceConsumptionRegression.npy', testX)\n",
    "np.save('testY_DailyResourceConsumptionRegression.npy', testY)\n",
    "\n",
    "#np.save('validX_DailyResourceConsumptionRegression.npy', validX)\n",
    "#np.save('validY_DailyResourceConsumptionRegression.npy', validY)\n",
    "\n",
    "\n",
    "\n",
    "#trainX = np.load(\"trainX_DHRegression.npy\")\n",
    "#trainY = np.load(\"trainY_DHRegression.npy\")\n",
    "#testX = np.load(\"testX_DHRegression.npy\")\n",
    "#testY = np.load(\"testY_DHRegression.npy\")\n",
    "#validX = np.load(\"validX_DHRegression.npy\")\n",
    "#validY = np.load(\"validY_DHRegression.npy\")\n",
    "\n",
    "trainX=pd.DataFrame(trainX,columns=data.columns)\n",
    "testX=pd.DataFrame(testX,columns=data.columns)\n",
    "trainY=pd.DataFrame(trainY,columns=labels.columns)\n",
    "testY=pd.DataFrame(testY,columns=labels.columns)\n",
    "\n",
    "\n",
    "print('trainX',trainX.min(),trainX.max())\n",
    "print('trainY',trainY.min(),trainY.max())\n",
    "print('testX',testX.min(),testX.max())\n",
    "print('testY',testY.min(),testY.max())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=Daily_Resource_Consumption[filenames[0]].columns\n",
    "idx=Daily_Resource_Consumption[filenames[0]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resourceConsumption=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Daily_Resource_Consumption[filenames[0]]=ss_y.transform(Daily_Resource_Consumption[filenames[0]])\n",
    "Daily_Resource_Consumption[filenames[1]]=ss_y.transform(Daily_Resource_Consumption[filenames[1]])\n",
    "Daily_Resource_Consumption[filenames[2]]=ss_y.transform(Daily_Resource_Consumption[filenames[2]])\n",
    "Daily_Resource_Consumption[filenames[3]]=ss_y.transform(Daily_Resource_Consumption[filenames[3]])\n",
    "Daily_Resource_Consumption[filenames[4]]=ss_y.transform(Daily_Resource_Consumption[filenames[4]])\n",
    "Daily_Resource_Consumption[filenames[5]]=ss_y.transform(Daily_Resource_Consumption[filenames[5]])\n",
    "\n",
    "Daily_Resource_Consumption[filenames[0]]=pd.DataFrame(Daily_Resource_Consumption[filenames[0]],columns=col,index=idx)\n",
    "Daily_Resource_Consumption[filenames[1]]=pd.DataFrame(Daily_Resource_Consumption[filenames[1]],columns=col,index=idx)\n",
    "Daily_Resource_Consumption[filenames[2]]=pd.DataFrame(Daily_Resource_Consumption[filenames[2]],columns=col,index=idx)\n",
    "Daily_Resource_Consumption[filenames[3]]=pd.DataFrame(Daily_Resource_Consumption[filenames[3]],columns=col,index=idx)\n",
    "Daily_Resource_Consumption[filenames[4]]=pd.DataFrame(Daily_Resource_Consumption[filenames[4]],columns=col,index=idx)\n",
    "Daily_Resource_Consumption[filenames[5]]=pd.DataFrame(Daily_Resource_Consumption[filenames[5]],columns=col,index=idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resourceConsumption[filenames[0]]=Daily_Resource_Consumption[filenames[0]].resample('W').sum()\n",
    "weekly_resourceConsumption[filenames[1]]=Daily_Resource_Consumption[filenames[1]].resample('W').sum()\n",
    "weekly_resourceConsumption[filenames[2]]=Daily_Resource_Consumption[filenames[2]].resample('W').sum()\n",
    "weekly_resourceConsumption[filenames[3]]=Daily_Resource_Consumption[filenames[3]].resample('W').sum()\n",
    "weekly_resourceConsumption[filenames[4]]=Daily_Resource_Consumption[filenames[4]].resample('W').sum()\n",
    "weekly_resourceConsumption[filenames[5]]=Daily_Resource_Consumption[filenames[5]].resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resourceConsumption[filenames[0]]=pd.DataFrame(weekly_resourceConsumption[filenames[0]],columns=col)\n",
    "weekly_resourceConsumption[filenames[1]]=pd.DataFrame(weekly_resourceConsumption[filenames[1]],columns=col)\n",
    "weekly_resourceConsumption[filenames[2]]=pd.DataFrame(weekly_resourceConsumption[filenames[2]],columns=col)\n",
    "weekly_resourceConsumption[filenames[3]]=pd.DataFrame(weekly_resourceConsumption[filenames[3]],columns=col)\n",
    "weekly_resourceConsumption[filenames[4]]=pd.DataFrame(weekly_resourceConsumption[filenames[4]],columns=col)\n",
    "weekly_resourceConsumption[filenames[5]]=pd.DataFrame(weekly_resourceConsumption[filenames[5]],columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resourceConsumption[filenames[0]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weekly_resourceConsumption[filenames[0]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_resourceConsumption[filenames[0]].to_csv(f'{filenames[0]}resource_consumption.csv')\n",
    "weekly_resourceConsumption[filenames[1]].to_csv(f'{filenames[1]}resource_consumption.csv')\n",
    "weekly_resourceConsumption[filenames[2]].to_csv(f'{filenames[2]}resource_consumption.csv')\n",
    "weekly_resourceConsumption[filenames[3]].to_csv(f'{filenames[3]}resource_consumption.csv')\n",
    "weekly_resourceConsumption[filenames[4]].to_csv(f'{filenames[4]}resource_consumption.csv')\n",
    "weekly_resourceConsumption[filenames[5]].to_csv(f'{filenames[5]}resource_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer,make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multioutput Regression\n",
    "\n",
    "models={#'LinearRegression':LinearRegression(fit_intercept=True,positive=True,n_jobs=-1),\n",
    "        'RandomForest':RandomForestRegressor( random_state = 42,\n",
    "                                            n_estimators=80,criterion='squared_error',\n",
    "                                            max_depth= None, min_samples_split = 2, min_samples_leaf= 1, min_weight_fraction_leaf = 0,\n",
    "                                            max_features='sqrt',max_leaf_nodes = None, min_impurity_decrease = 0, bootstrap=True,\n",
    "                                            oob_score  = False, n_jobs = None, verbose = 0, warm_start = True,\n",
    "                                            ccp_alpha = 0, max_samples=None\n",
    "                                             ),\n",
    "        'GradientBoosting':GradientBoostingRegressor(random_state=42),\n",
    "        'AdaBoost':AdaBoostRegressor(random_state=42),\n",
    "        'KNeighborsRegressor':KNeighborsRegressor(n_neighbors= 7, weights='distance', algorithm='ball_tree', leaf_size = 50,\n",
    "                                                   p= 4, metric = \"minkowski\",metric_params = None, n_jobs=-1),\n",
    "        'DecisionTree':DecisionTreeRegressor(random_state=42),\n",
    "        #'LinearSVR':LinearSVR(max_iter=50000,random_state=42),\n",
    "        'SVR':  SVR(max_iter=50000)\n",
    "        }\n",
    "\n",
    "num_attributes=data.columns\n",
    "cat_attributes=[]\n",
    "outputs=labels.columns\n",
    "num_pipline=make_pipeline(SimpleImputer())\n",
    "cat_pipeline=make_pipeline(OneHotEncoder())\n",
    "\n",
    "preprocessing=ColumnTransformer([('num', num_pipline, num_attributes),\n",
    "                                ('cat',cat_pipeline,cat_attributes),\n",
    "                                ])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\n",
    "\n",
    "outputs=teams_drc.columns\n",
    "train_results=dict()\n",
    "train_results[outputs[0]]=[] \n",
    "train_results[outputs[1]]=[]\n",
    "train_results[outputs[2]]=[]\n",
    "train_results[outputs[3]]=[]\n",
    "train_results[outputs[4]]=[]\n",
    "train_results[outputs[5]]=[]\n",
    "test_results=dict()\n",
    "test_results[outputs[0]]=[] \n",
    "test_results[outputs[1]]=[]\n",
    "test_results[outputs[2]]=[]\n",
    "test_results[outputs[3]]=[]\n",
    "test_results[outputs[4]]=[]\n",
    "test_results[outputs[5]]=[]\n",
    "\n",
    "conf_interv_results=dict()\n",
    "conf_interv_results[outputs[0]]=[]\n",
    "conf_interv_results[outputs[1]]=[]\n",
    "conf_interv_results[outputs[2]]=[]\n",
    "conf_interv_results[outputs[3]]=[]\n",
    "conf_interv_results[outputs[4]]=[]\n",
    "conf_interv_results[outputs[5]]=[]\n",
    "\n",
    "train_rmse=dict()\n",
    "train_r2=dict()\n",
    "train_mse=dict()\n",
    "test_rmse=dict()\n",
    "test_r2=dict()\n",
    "test_mse=dict()\n",
    "c1=dict()\n",
    "c2=dict()\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "import joblib\n",
    "\n",
    "for key in models.keys():\n",
    "\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('models',RegressorChain(models[key],order=[0,1,2,3,4,5],random_state=42)),\n",
    "        #('models',MultiOutputRegressor(models[key],n_jobs=-1)),\n",
    "    ])\n",
    "    #train\n",
    "    score=cross_validate(full_pipeline, trainX, trainY,scoring='neg_root_mean_squared_error', cv=10)\n",
    "    full_pipeline.fit(trainX, trainY)\n",
    "    train_prediction=cross_val_predict(full_pipeline,trainX,trainY,cv=3)\n",
    "    \n",
    "    #train_prediction=min_max_scaler.inverse_transform(train_prediction)\n",
    "    test_prediction=cross_val_predict(full_pipeline,testX,testY,cv=3)\n",
    "    #train_prediction=min_max_scaler.inverse_transform(test_prediction)\n",
    "    joblib.dump(full_pipeline,f'{key}DailyResourceConsumptionEstimator.pkl')    \n",
    "    #loaded_model=joblib.load(f'{key}DailyResourceConsumptionEstimator.pkl')    \n",
    "    #new_data=testX\n",
    "    #predictions=loaded_model.predict(new_data)\n",
    "    #print(predictions,testY)    \n",
    "    for i,out in zip(range(0,len(labels.columns),1),labels.columns):\n",
    "        #train scores:\n",
    "        train_rmse[out]=mean_squared_error(y_pred=train_prediction[:,i],y_true=trainY[out])/labels[out].mean()\n",
    "        train_mse[out]=mean_squared_error(y_pred=train_prediction[:,i],y_true=trainY[out])/labels[out].mean()\n",
    "        train_r2[out]=r2_score(y_true=trainY[out],y_pred=train_prediction[:,i])\n",
    "        #train result for each output\n",
    "        train_results[out].append((key,train_rmse[out],train_mse[out],train_r2[out]))\n",
    "       \n",
    "        #test scores:\n",
    "        test_rmse[out]=mean_squared_error(y_pred=test_prediction[:,i],y_true=testY[out])/labels[out].mean()\n",
    "        test_mse[out]=mean_squared_error(y_pred=test_prediction[:,i],y_true=testY[out])/labels[out].mean()\n",
    "        test_r2[out]=r2_score(y_true=testY[out],y_pred=test_prediction[:,i])\n",
    "        #test result for each output\n",
    "        test_results[out].append((key,test_rmse[out],test_mse[out],test_r2[out]))\n",
    "        \n",
    "        from scipy import stats\n",
    "        #confidence_interval:\n",
    "        confidence = 0.95\n",
    "        #print(test_prediction[:,i].shape,testY[out].shape)\n",
    "        squared_errors = (test_prediction[:,i] - testY[out]) ** 2\n",
    "        zscore = stats.norm.ppf((1 + confidence) / 2)\n",
    "        zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(len(squared_errors))\n",
    "        c1[out] = np.sqrt(squared_errors.mean() - zmargin)/labels[out].mean()\n",
    "        c2[out]= np.sqrt(squared_errors.mean() + zmargin)/labels[out].mean()\n",
    "        #confidence_intervals for each output:\n",
    "        conf_interv_results[out].append((key,test_rmse[out],c1[out],c2[out],c2[out]-c1[out]))\n",
    "        \n",
    "#        # Plot predicted vs actual\n",
    "#        plt.figure\n",
    "#        plt.style.use(\"ggplot\")\n",
    "#        plt.scatter(testY[out], test_prediction[:,i],color='steelblue')\n",
    "#        plt.xlabel(f'Actual {out}')\n",
    "#        plt.ylabel(f'Predicted {out}')\n",
    "#        plt.title(f'predicted vs actual {out} \\nplot for {key}',fontsize=12)\n",
    "#        # overlay the regression line\n",
    "#        z = np.polyfit(testY[out], test_prediction[:,i], 1)\n",
    "#        p = np.poly1d(z)\n",
    "#        plt.plot(testY[out],p(testY[out]),color='red')\n",
    "#        #plt.grid()\n",
    "#        save_fig(f'predicted vs actual {out} plot for {key}')\n",
    "#        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        from scipy import stats\n",
    "        #confidence_interval:\n",
    "        confidence = 0.95\n",
    "        squared_errors = (test_prediction[:,i] - testY[out]) ** 2\n",
    "        zscore = stats.norm.ppf((1 + confidence) / 2)\n",
    "        zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(len(squared_errors))\n",
    "        c1[out] = np.sqrt(squared_errors.mean() - zmargin)/labels[out].mean()\n",
    "        c2[out] = np.sqrt(squared_errors.mean() + zmargin)/labels[out].mean()\n",
    "        #confidence_intervals for each output:\n",
    "        conf_interv_results[out].append((key,test_rmse[out],c1[out],c2[out],c2[out]-c1[out]))\n",
    "        \n",
    "\n",
    "    \n",
    "print(train_results[outputs[0]],'\\n',train_results[outputs[1]],'\\n',train_results[outputs[2]],\n",
    "      '\\n',train_results[outputs[3]],'\\n',train_results[outputs[4]],'\\n',train_results[outputs[5]],'\\n')\n",
    "print(test_results[outputs[0]],'\\n',test_results[outputs[1]],'\\n',test_results[outputs[2]],'\\n',\n",
    "      test_results[outputs[3]],'\\n',test_results[outputs[4]],'\\n',test_results[outputs[5]],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show training results table:\n",
    "best_trained_model_idx=dict()\n",
    "train_result=dict()\n",
    "\n",
    "for out in outputs:\n",
    "    print(f'best models train {out} scores:',train_results[out])\n",
    "    best_trained_model_idx[out]=np.array(train_results[out])[:,1].argmin()\n",
    "\n",
    "\n",
    "    #print('best models test scores:',test_results)\n",
    "    #best_tested_model_idx=np.array(test_results)[:,1].argmax()\n",
    "\n",
    "    print('best trained model:',train_results[out][best_trained_model_idx[out]][0],\n",
    "                            train_results[out][best_trained_model_idx[out]][1],'\\n')\n",
    "\n",
    "\n",
    "    #print('best tested model:',test_results[best_tested_model_idx][0],test_results[best_tested_model_idx][1])\n",
    "    train_result[out]=pd.DataFrame(train_results[out],\n",
    "               columns=['Model','RMSE','MSE','R2_Score']).sort_values(by='RMSE')\n",
    "\n",
    "    #dfi.export(train_result, \"ModelsTrainingResultsTable.png\")\n",
    "    print(train_result[out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0],'\\n')\n",
    "train_result[outputs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[1],'\\n')\n",
    "train_result[outputs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[2],'\\n')\n",
    "train_result[outputs[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[3],'\\n')\n",
    "train_result[outputs[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[4],'\\n')\n",
    "train_result[outputs[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[5],'train result\\n')\n",
    "train_result[outputs[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show training results table:\n",
    "best_trained_model_idx=dict()\n",
    "test_result=dict()\n",
    "\n",
    "for out in outputs:\n",
    "    print(f'best models train {out} scores:',test_results[out])\n",
    "    best_trained_model_idx[out]=np.array(test_results[out])[:,1].argmin()\n",
    "\n",
    "\n",
    "    #print('best models test scores:',test_results)\n",
    "    #best_tested_model_idx=np.array(test_results)[:,1].argmax()\n",
    "\n",
    "    print('best trained model:',test_results[out][best_trained_model_idx[out]][0],\n",
    "                            test_results[out][best_trained_model_idx[out]][1],'\\n')\n",
    "\n",
    "\n",
    "    #print('best tested model:',test_results[best_tested_model_idx][0],test_results[best_tested_model_idx][1])\n",
    "    test_result[out]=pd.DataFrame(test_results[out],\n",
    "               columns=['Model','RMSE','MSE','R2_Score']).sort_values(by='RMSE')\n",
    "\n",
    "    #dfi.export(test_result, \"ModelsTrainingResultsTable.png\")\n",
    "    print(test_result[out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0],'test result\\n')\n",
    "test_result[outputs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[1],'test result','\\n')\n",
    "test_result[outputs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[2],'test result\\n')\n",
    "test_result[outputs[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[3],'test result\\n')\n",
    "test_result[outputs[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[4],'test result\\n')\n",
    "test_result[outputs[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[5],'test result\\n')\n",
    "test_result[outputs[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_interv_result=dict()\n",
    "for out in outputs:\n",
    "\n",
    "    print(conf_interv_results[out],'\\n')\n",
    "\n",
    "    \n",
    "    conf_interv_result[out]=pd.DataFrame(conf_interv_results[out],\n",
    "               columns=['Model','RMSE','C1','C2','Confidence Interval']).sort_values(by='RMSE',ignore_index=True)\n",
    "\n",
    "    \n",
    "    conf_interv_result[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0],'\\n')\n",
    "conf_interv_result[outputs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[1],'\\n')\n",
    "conf_interv_result[outputs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[2],'\\n')\n",
    "conf_interv_result[outputs[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[3],'\\n')\n",
    "conf_interv_result[outputs[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[4],'\\n')\n",
    "conf_interv_result[outputs[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[5],'\\n')\n",
    "conf_interv_result[outputs[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out in outputs:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.xticks(range(len(conf_interv_result[out])),list(conf_interv_result[out]['Model']),\n",
    "                rotation = 90, ha=\"right\")\n",
    "    plt.title(f'RMSE Confidence Intevals of {out}\\n for Classical ML Models',fontsize=12)\n",
    "    for C1,C2,b in zip(conf_interv_result[out]['C1'],conf_interv_result[out]['C2'],\n",
    "                        range(len(conf_interv_result[out]))):\n",
    "        color='#2187bb'\n",
    "        horizontal_line_width=0.25\n",
    "        left = b - horizontal_line_width / 4\n",
    "        right = b + horizontal_line_width / 4\n",
    "        #plt.plot((b,b),(C1,C2),'ro-',color='orange')\n",
    "        plt.plot([b, b], [C2, C1], color=color)\n",
    "        plt.plot([left, right], [C2, C2], color=color)\n",
    "        plt.plot([left, right], [C1, C1], color=color)\n",
    "        plt.plot(b, conf_interv_result[out]['RMSE'][b], 'o', color='#f44336')\n",
    "    save_fig(f'RMSE_Confidence_Intevals_{out}_ML_Models')\n",
    "\n",
    "    #plt.xticks(range(len(confidence_interval_results)),list(confidence_interval_results['Model']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pred_out,i in zip(outputs,range(len(outputs))):\n",
    "#    plt.style.use(\"ggplot\")\n",
    "#    plt.figure()\n",
    "#    plt.plot(test_prediction[:,i][15:50],label='predected', marker=\".\")\n",
    "#    plt.plot(testY[pred_out].values[15:50],label='Actual',marker=\".\")\n",
    "#\n",
    "#    plt.title(f\"Predicted Vs. Actual of {pred_out} \\nsamples of {Chain Regressorgressor}\",fontsize=12)\n",
    "#    plt.xlabel(\"samples\")\n",
    "#    plt.ylabel(f\"{pred_out}\")\n",
    "#    plt.legend(loc=\"lower left\")\n",
    "#    save_fig(f\"Predicted Vs. Actual of {pred_out} in discrete time series points of Chain Regressor\")\n",
    "#\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "\n",
    "\n",
    "outputs=teams_drc.columns\n",
    "train_results=dict()\n",
    "train_results[outputs[0]]=[] \n",
    "train_results[outputs[1]]=[]\n",
    "train_results[outputs[2]]=[]\n",
    "train_results[outputs[3]]=[]\n",
    "train_results[outputs[4]]=[]\n",
    "train_results[outputs[5]]=[]\n",
    "test_results=dict()\n",
    "test_results[outputs[0]]=[] \n",
    "test_results[outputs[1]]=[]\n",
    "test_results[outputs[2]]=[]\n",
    "test_results[outputs[3]]=[]\n",
    "test_results[outputs[4]]=[]\n",
    "test_results[outputs[5]]=[]\n",
    "\n",
    "conf_interv_results=dict()\n",
    "conf_interv_results[outputs[0]]=[]\n",
    "conf_interv_results[outputs[1]]=[]\n",
    "conf_interv_results[outputs[2]]=[]\n",
    "conf_interv_results[outputs[3]]=[]\n",
    "conf_interv_results[outputs[4]]=[]\n",
    "conf_interv_results[outputs[5]]=[]\n",
    "\n",
    "train_rmse=dict()\n",
    "train_r2=dict()\n",
    "train_mse=dict()\n",
    "test_rmse=dict()\n",
    "test_r2=dict()\n",
    "test_mse=dict()\n",
    "c1=dict()\n",
    "c2=dict()\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "\n",
    "\n",
    "estimator=RandomForestRegressor(n_estimators= 100,criterion='squared_error',\n",
    "    max_depth= None,min_samples_split= 2,min_samples_leaf= 1,min_weight_fraction_leaf= 0,max_features='sqrt',\n",
    "    max_leaf_nodes= None,min_impurity_decrease= 0,bootstrap= True,oob_score=False,n_jobs= -1,\n",
    "    ccp_alpha=0,max_samples= None,random_state=42)\n",
    "\n",
    "best_models=dict()\n",
    "\n",
    "best_models['Chain_Regressor']=RegressorChain(base_estimator=estimator,order=[0,1,2,3,4,5],random_state=42)\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('Chain_Regressor',best_models['Chain_Regressor'] )\n",
    "                        ])\n",
    "       \n",
    "param_grid=[{ \n",
    "                'Chain_Regressor__base_estimator__max_depth':[2,6,None,8],\n",
    "                'Chain_Regressor__base_estimator__n_estimators':[100,120,150,200,300,500],\n",
    "                'Chain_Regressor__base_estimator__criterion':['squared_error','friedman_mse'],\n",
    "                'Chain_Regressor__base_estimator__min_samples_split':[2,10,8],\n",
    "                'Chain_Regressor__base_estimator__max_samples':[None,100,20,80],\n",
    "                'Chain_Regressor__base_estimator__max_features':['sqrt','log2'],\n",
    "                'Chain_Regressor__base_estimator__ccp_alpha':[0,.1,.01,10,1],              \n",
    "            }]\n",
    "grid_search=GridSearchCV(full_pipeline,param_grid,cv=10,scoring='neg_root_mean_squared_error',verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.fit(trainX,trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_prediction=cross_val_predict(grid_search.best_estimator_,trainX,trainY,cv=3)\n",
    "#test_prediction=cross_val_predict(grid_search.best_estimator_,testX,testY,cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#for i,out in zip(range(0,len(labels.columns),1),labels.columns):\n",
    "#    #train scores:\n",
    "#    train_rmse[out]=mean_squared_error(y_pred=train_prediction[:,i],y_true=trainY[out])/labels[out].mean()\n",
    "#    train_mse[out]=mean_squared_error(y_pred=train_prediction[:,i],y_true=trainY[out])/labels[out].mean()\n",
    "#    train_r2[out]=r2_score(y_true=trainY[out],y_pred=train_prediction[:,i])\n",
    "#    #train result for each output\n",
    "#    train_results[out].append(('Chain_Regressor',train_rmse[out],train_mse[out],train_r2[out]))\n",
    "#   \n",
    "#    #test scores:\n",
    "#    test_rmse[out]=mean_squared_error(y_pred=test_prediction[:,i],y_true=testY[out])/labels[out].mean()\n",
    "#    test_mse[out]=mean_squared_error(y_pred=test_prediction[:,i],y_true=testY[out])/labels[out].mean()\n",
    "#    test_r2[out]=r2_score(y_true=testY[out],y_pred=test_prediction[:,i])\n",
    "#    #test result for each output\n",
    "#    test_results[out].append(('Chain_Regressor',test_rmse[out],test_mse[out],test_r2[out]))\n",
    "#    \n",
    "#    # Plot predicted vs actual\n",
    "#    plt.style.use(\"ggplot\")\n",
    "#    plt.scatter(testY[out], test_prediction[:,i],color='steelblue')\n",
    "#    plt.xlabel(f'Actual {out}')\n",
    "#    plt.ylabel(f'Predicted {out}')\n",
    "#    plt.title(f'predicted vs actual {out} \\nplot for Chain Regressor',fontsize=12)\n",
    "#    # overlay the regression line\n",
    "#    z = np.polyfit(testY[out], test_prediction[:,i], 1)\n",
    "#    p = np.poly1d(z)\n",
    "#    plt.plot(testY[out],p(testY[out]),color='red')\n",
    "#    #plt.grid()\n",
    "#    save_fig(f'predicted vs actual {out} plot for Chain Regressor')\n",
    "#    plt.show()\n",
    "#\n",
    "#\n",
    "#\n",
    "#    from scipy import stats\n",
    "#    #confidence_interval:\n",
    "#    confidence = 0.95\n",
    "#    squared_errors = (test_prediction[:,i] - testY[out]) ** 2\n",
    "#    zscore = stats.norm.ppf((1 + confidence) / 2)\n",
    "#    zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(len(squared_errors))\n",
    "#    c1[out] = np.sqrt(squared_errors.mean() - zmargin)/labels[out].mean()\n",
    "#    c2[out] = np.sqrt(squared_errors.mean() + zmargin)/labels[out].mean()\n",
    "#    #confidence_intervals for each output:\n",
    "#    conf_interv_results[out].append(('Chain_Regressor',test_rmse[out],c1[out],c2[out],c2[out]-c1[out]))\n",
    "#    \n",
    "#print(train_results[outputs[0]],'\\n',train_results[outputs[1]],'\\n',train_results[outputs[2]],'\\n',\n",
    "#      train_results[outputs[3]],'\\n',train_results[outputs[4]],'\\n',train_results[outputs[5]],'\\n')\n",
    "#print(test_results[outputs[0]],'\\n',test_results[outputs[1]],'\\n',test_results[outputs[2]],'\\n',\n",
    "#      test_results[outputs[3]],'\\n',test_results[outputs[4]],'\\n',test_results[outputs[5]],'\\n')\n",
    "#print(conf_interv_results[outputs[0]],'\\n',conf_interv_results[outputs[1]],'\\n',conf_interv_results[outputs[2]],'\\n',\n",
    "#      conf_interv_results[outputs[3]],'\\n',conf_interv_results[outputs[4]],'\\n',conf_interv_results[outputs[5]],'\\n')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pred_out,i in zip(outputs,range(len(outputs))):\n",
    "#    plt.style.use(\"ggplot\")\n",
    "#    plt.figure()\n",
    "#    plt.plot(test_prediction[:,i][15:50],label='predected', marker=\".\")\n",
    "#    plt.plot(testY[pred_out].values[15:50],label='Actual',marker=\".\")\n",
    "#\n",
    "#    plt.title(f\"Predicted Vs. Actual of {pred_out} \\nsamples of Chain Regressor\",fontsize=12)\n",
    "#    plt.xlabel(\"samples\")\n",
    "#    plt.ylabel(f\"{pred_out}\")\n",
    "#    plt.legend(loc=\"lower left\")\n",
    "#    save_fig(f\"Predicted Vs. Actual of {pred_out} in discrete time series points of Chain Regressor\")\n",
    "#\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params=grid_search.best_params_\n",
    "##best_params['RandomForestRegressor__base_estimator']=grid_search.best_estimator_['RandomForestRegressor__base_estimator'].n_estimators_\n",
    "#GBR_best_param=pd.DataFrame.from_dict(grid_search.best_params_,orient='index',columns=['best value'])\n",
    "#GBR_best_param['best value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##show training results table:\n",
    "#best_trained_model_idx=dict()\n",
    "#test_result=dict()\n",
    "#\n",
    "#for out in outputs:\n",
    "#    print(f'best models train {out} scores:',test_results[out])\n",
    "#    best_trained_model_idx[out]=np.array(test_results[out])[:,1].argmin()\n",
    "#\n",
    "#\n",
    "#    #print('best models test scores:',test_results)\n",
    "#    #best_tested_model_idx=np.array(test_results)[:,1].argmax()\n",
    "#\n",
    "#    print('best trained model:',test_results[out][best_trained_model_idx[out]][0],\n",
    "#                            test_results[out][best_trained_model_idx[out]][1],'\\n')\n",
    "#\n",
    "#\n",
    "#    #print('best tested model:',test_results[best_tested_model_idx][0],test_results[best_tested_model_idx][1])\n",
    "#    test_result[out]=pd.DataFrame(test_results[out],\n",
    "#               columns=['Model','RMSE','MSE','R2_Score']).sort_values(by='RMSE')\n",
    "#\n",
    "#    #dfi.export(test_result, \"ModelsTrainingResultsTable.png\")\n",
    "#    print(test_result[out])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs[0],'\\n')\n",
    "#test_result[outputs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs[1],'\\n')\n",
    "#test_result[outputs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs[2],'\\n')\n",
    "#test_result[outputs[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs[3],'\\n')\n",
    "#test_result[outputs[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs[4],'\\n')\n",
    "#test_result[outputs[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(outputs[5],'\\n')\n",
    "#test_result[outputs[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##grid_search.best_estimator_.save('DailyResourceConsumptionEstimator.pkl')\n",
    "#\n",
    "#import joblib\n",
    "#\n",
    "#joblib.dump(grid_search.best_estimator_,'DailyResourceConsumptionEstimator.pkl')\n",
    "#\n",
    "#loaded_model=joblib.load('DailyResourceConsumptionEstimator.pkl')\n",
    "#\n",
    "#new_data=testX\n",
    "#predictions=loaded_model.predict(new_data)\n",
    "#print(predictions,testY)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#joblib.dump(models['GradientBoosting'],'GradientBoostingDailyResourceConsumptionEstimator.pkl')\n",
    "\n",
    "\n",
    "loaded_model=joblib.load('GradientBoostingDailyResourceConsumptionEstimator.pkl')\n",
    "\n",
    "new_data=testX\n",
    "predictions=loaded_model.predict(new_data)\n",
    "print(predictions,testY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
